{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "mlp_exercise.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN7V6N1KS-cH"
      },
      "source": [
        "# MLP -- exercise\n",
        "\n",
        "# Understanding the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5fC1VQxS-cK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVU2h_VvS-cS"
      },
      "source": [
        "### Download the data and print the shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54LAU_tVS-cU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd3a5be3-aad7-4daf-a3a2-24e02186bbad"
      },
      "source": [
        "\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Apply transformations to the data points before passing them to the network\n",
        "transform = transforms.Compose([transforms.ToTensor(),  # Transform the data to torch tensors of shape (28, 28, 1), corresponding to 28 * 28 pixels with 1 channel (1 value per pixel that is)\n",
        "                                transforms.Lambda(lambda x: x.squeeze()),  # Squeeze the data to remove the redundant channel dimension\n",
        "                                ])                                         # Note: This is only redundant because there is only one channel\n",
        "\n",
        "# Download the MNIST train dataset (used to train the network)\n",
        "trainset = torchvision.datasets.FashionMNIST(root='./data_FashionMNIST',\n",
        "                                      train=True,\n",
        "                                      download=True,\n",
        "                                      transform=transform  # Apply the defined transformation on the data\n",
        "                                      )\n",
        "\n",
        "# Download the MNIST test dataset (used to evaluate the trained network)\n",
        "testset = torchvision.datasets.FashionMNIST(root='./data_FashionMNIST',\n",
        "                                     train=False,\n",
        "                                     download=True,\n",
        "                                     transform=transform\n",
        "                                     )\n",
        "\n",
        "classes = (\n",
        "    'T-shirt/top',\n",
        "    'Trouser',\n",
        "    'Pullover',\n",
        "    'Dress',\n",
        "    'Coat',\n",
        "    'Sandal',\n",
        "    'Shirt',\n",
        "    'Sneaker',\n",
        "    'Bag',\n",
        "    'Ankle boot',\n",
        ")\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 17.8MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 308kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.59MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 16.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkmlPuOdS-cY",
        "outputId": "b5944245-0185-4910-a8e4-1039c4249abe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(trainset.data.shape)  # The trainset consists of 60000 28x28 images"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpO5_X8nS-cm"
      },
      "source": [
        "### Make a ONE layer net class **without** softmax activation\n",
        "We will use PyTorch's cross entropy loss function which expects the model outputs directly as it applies the softmax function internally. Therefore you only need to implement one linear layer with `input_size` number of inputs and `output_size` number of outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vvF91K_S-cn"
      },
      "source": [
        "class OneLayerNet(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(OneLayerNet , self).__init__()\n",
        "        self.linear_layer = nn.Linear( input_size, output_size , bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        scores = self.linear_layer(x)\n",
        "        return scores\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSnd8DJuS-cq"
      },
      "source": [
        "### Build the net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErU8ayfQS-cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d9bd7f9-9e1c-4636-b7af-0f2633e10c98"
      },
      "source": [
        "net=  OneLayerNet(784, 10)\n",
        "print(net)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OneLayerNet(\n",
            "  (linear_layer): Linear(in_features=784, out_features=10, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uatdAdjOS-cv"
      },
      "source": [
        "### Choose the criterion and the optimizer: use the CHEAT SHEET to see the correct syntax.\n",
        "\n",
        "### Remember that the optimizer need to have access to the parameters of the network (net.parameters()).\n",
        "\n",
        "### Set the batchize and learning rate to be:\n",
        "### batchize = 50\n",
        "### learning rate = 0.01\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwpar7DoS-cx"
      },
      "source": [
        "# make the criterion\n",
        "criterion =  nn.CrossEntropyLoss() # complete here\n",
        "\n",
        "# make the SGD optimizer.\n",
        "optimizer=torch.optim.SGD(net.parameters(),lr=0.01)\n",
        "\n",
        "# set up the batch size\n",
        "bs=50"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvFafa9icQyO"
      },
      "source": [
        "### Create DataLoaders that sample data from the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5IQ1XI8cQ_g"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                          batch_size=bs,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True\n",
        "                                          )\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset,\n",
        "                                         batch_size=bs,\n",
        "                                         shuffle=True,\n",
        "                                         drop_last=True\n",
        "                                         )"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBIVatHBS-c0"
      },
      "source": [
        "### Complete the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNuAEBaGS-c1"
      },
      "source": [
        "# Every epoch you iterate once over the entire dataset\n",
        "for epoch in range(1, 5):\n",
        "  # The trainloader splits the train dataset into random minibatches of data\n",
        "  # Iterate through all minibatches in the data set and perform gradient descent\n",
        "  for i, (minibatch_data, minibatch_label) in enumerate(trainloader):\n",
        "\n",
        "      # Set dL/dU, dL/dV, dL/dW to be filled with zeros\n",
        "      optimizer.zero_grad()\n",
        "      # reshape the minibatch\n",
        "      input = minibatch_data.view(bs,784)\n",
        "      # forward the minibatch through the net\n",
        "      minibatch_prediction = net(input)\n",
        "      # Compute the average of the losses of the data points in the minibatch\n",
        "      loss = criterion(minibatch_prediction, minibatch_label)\n",
        "      # backward pass to compute dL/dU, dL/dV and dL/dW\n",
        "      loss.backward()\n",
        "\n",
        "      # do one step of stochastic gradient descent: U=U-lr(dL/dU), V=V-lr(dL/dU), ...\n",
        "      optimizer.step()\n",
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1WidPb4S-c4"
      },
      "source": [
        "### Choose image at random from the test set and see how good/bad are the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrpUXb1vS-c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "outputId": "4586441b-cb04-4a7e-a65e-540c7a47ac33"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# choose a picture at random\n",
        "im_minibatch, label_minibatch = next(iter(testloader))\n",
        "im, label = im_minibatch[0], label_minibatch[0]\n",
        "\n",
        "# Function to show an image tensor\n",
        "def show(X):\n",
        "    if X.dim() == 3 and X.size(2) == 3:\n",
        "        plt.imshow(X.numpy())\n",
        "        plt.show()\n",
        "    elif X.dim() == 2:\n",
        "        plt.imshow(   X.numpy() , cmap='gray'  )\n",
        "        plt.show()\n",
        "    else:\n",
        "        print('WRONG TENSOR SIZE')\n",
        "\n",
        "# diplay the picture\n",
        "show(im)\n",
        "\n",
        "# feed it to the net and display the confidence scores\n",
        "prob = F.softmax(net( im.view(1,784)), dim=1)  # Apply softmax to normalize the output to a probability distribution\n",
        "\n",
        "print('Confidence scores:\\n' + '\\n'.join(['{:12s}: {}'.format(classes[i], p.item()) for i, p in enumerate(prob.squeeze())]))\n",
        "\n",
        "print('\\nLabel with highest confidence score: {}'.format(classes[torch.argmax(prob).item()]))\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence scores:\n",
            "T-shirt/top : 0.06616131216287613\n",
            "Trouser     : 0.0037787107285112143\n",
            "Pullover    : 0.06449408084154129\n",
            "Dress       : 0.1104961633682251\n",
            "Coat        : 0.007475805934518576\n",
            "Sandal      : 0.02852053940296173\n",
            "Shirt       : 0.08503345400094986\n",
            "Sneaker     : 0.02146334946155548\n",
            "Bag         : 0.05750375613570213\n",
            "Ankle boot  : 0.5550728440284729\n",
            "\n",
            "Label with highest confidence score: Ankle boot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD0_VL2BS-c6"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}