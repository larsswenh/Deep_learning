{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM2M1Tn73NQ5"
      },
      "source": [
        "# LeNet5 on MNIST\n",
        "In this lab we will train a LeNet5 model on the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeBGrEwi06fz"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Vufhok43UWG"
      },
      "source": [
        "It is recommended to use the GPU for this exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTnvxLin1LNV",
        "outputId": "8925d9a2-5469-425f-e887-75eecd1fbc24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "use_cuda = True\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzu-t97vF7y4"
      },
      "source": [
        "Define a function to show images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h5iFcBkC3ui"
      },
      "source": [
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to show an image tensor\n",
        "def show(X):\n",
        "    if X.dim() == 3 and X.size(2) == 3:\n",
        "        plt.imshow(X.numpy())\n",
        "        plt.show()\n",
        "    elif X.dim() == 2:\n",
        "        plt.imshow(   X.numpy() , cmap='gray'  )\n",
        "        plt.show()\n",
        "    else:\n",
        "        print('WRONG TENSOR SIZE')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYGgIG8SGIr9"
      },
      "source": [
        "### Load the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40KsWyBt2qmv",
        "outputId": "832cd19b-2d9c-42ea-be77-0e2ede349bf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.1307,), (0.3081,)),  # Normalize the dataset by subtracting the mean (0.1307) and dividing by the std (0.3081)\n",
        "                                ])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data_mnist',\n",
        "                                      train=True,\n",
        "                                      download=True,\n",
        "                                      transform=transform\n",
        "                                      )\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data_mnist',\n",
        "                                     train=False,\n",
        "                                     download=True,\n",
        "                                     transform=transform\n",
        "                                     )\n",
        "\n",
        "batch_size = 80\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          )\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=True,\n",
        "                                         )\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 501kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.66MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.88MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLHJlUyjGNhA"
      },
      "source": [
        "### Define the LeNet5 architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkHt81xb2-SN"
      },
      "source": [
        "class LeNet5_convnet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(LeNet5_convnet, self).__init__()\n",
        "\n",
        "        # Conv Layer 1:   28 x 28  -->    50 x 28 x 28\n",
        "        self.conv1 = nn.Conv2d(1, 50, kernel_size=3, padding=1)\n",
        "\n",
        "        # Max Pool 1: 50 x 28 x 28 -->    50 x 14 x 14\n",
        "        self.pool1  = nn.MaxPool2d(2,2)\n",
        "\n",
        "        # CL2:   50 x 14 x 14  -->    100 x 14 x 14\n",
        "        self.conv2 = nn.Conv2d(50, 100, kernel_size=3, padding=1) # COMPLETE HERE\n",
        "\n",
        "        # MP2: 100 x 14 x 14 -->    100 x 7 x 7\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        # LL1:   100 x 7 x 7 = 4900 -->  100\n",
        "        self.linear1 = nn.Linear(in_features=4900, out_features=100)\n",
        "\n",
        "        # LL2:   100  -->  10\n",
        "        self.linear2 = nn.Linear(in_features=100, out_features=10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # CL1:   28 x 28  -->    50 x 28 x 28\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # MP1: 50 x 28 x 28 -->    50 x 14 x 14\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # CL2:   50 x 14 x 14  -->    100 x 14 x 14\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # MP2: 100 x 14 x 14 -->    100 x 7 x 7\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # LL1:   100 x 7 x 7 = 4900  -->  100\n",
        "        x = x.view(-1, 4900)\n",
        "        x = self.linear1(x) # COMPLETE HERE -- recall that you need to flatten the data before you can pass it to the dense layer!\n",
        "\n",
        "        # LL2:   100  -->  10\n",
        "        x = self.linear2(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4iagyWQ6Axl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b4906b-82f4-4d85-9e22-b6f82a706a6f"
      },
      "source": [
        "# Build the network and move its parameters to either GPU or CPU\n",
        "net = LeNet5_convnet()\n",
        "net.to(device='cuda')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet5_convnet(\n",
              "  (conv1): Conv2d(1, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(50, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (linear1): Linear(in_features=4900, out_features=100, bias=True)\n",
              "  (linear2): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3Pc9fdnKDk3"
      },
      "source": [
        "### Choose a loss function and learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvENiJAt6Auj"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "my_lr = 0.01\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etpYx0fIHNvc"
      },
      "source": [
        "### Train the model on the train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmSJpneX6ApZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408465bc-ee5f-4549-c821-713824f14d58"
      },
      "source": [
        "start=time.time()\n",
        "\n",
        "optimizer=torch.optim.SGD(net.parameters(), lr=my_lr)\n",
        "\n",
        "for epoch in range(1,10):\n",
        "\n",
        "  for i, (x_batch, y_batch) in enumerate(trainloader):\n",
        "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
        "\n",
        "    optimizer.zero_grad()  # Set all currenly stored gradients to zero\n",
        "\n",
        "    y_pred = net(x_batch)\n",
        "\n",
        "    loss = criterion(y_pred, y_batch)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    # Compute relevant metrics\n",
        "\n",
        "    y_pred_max = torch.argmax(y_pred, dim=1)  # Get the labels with highest output probability\n",
        "\n",
        "    correct = torch.sum(torch.eq(y_pred_max, y_batch)).item()  # Count how many are equal to the true labels\n",
        "\n",
        "    elapsed = time.time() - start  # Keep track of how much time has elapsed\n",
        "\n",
        "    # Show progress every 20 batches\n",
        "    if not i % 20:\n",
        "      print(f'epoch: {epoch}, time: {elapsed:.3f}s, loss: {loss.item():.3f}, train accuracy: {correct / batch_size:.3f}')\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, time: 1.146s, loss: 2.313, train accuracy: 0.075\n",
            "epoch: 1, time: 1.559s, loss: 1.894, train accuracy: 0.550\n",
            "epoch: 1, time: 1.940s, loss: 1.234, train accuracy: 0.675\n",
            "epoch: 1, time: 2.325s, loss: 0.848, train accuracy: 0.787\n",
            "epoch: 1, time: 2.698s, loss: 0.719, train accuracy: 0.775\n",
            "epoch: 1, time: 3.089s, loss: 0.523, train accuracy: 0.800\n",
            "epoch: 1, time: 3.493s, loss: 0.425, train accuracy: 0.850\n",
            "epoch: 1, time: 3.874s, loss: 0.669, train accuracy: 0.775\n",
            "epoch: 1, time: 4.266s, loss: 0.437, train accuracy: 0.887\n",
            "epoch: 1, time: 4.786s, loss: 0.467, train accuracy: 0.863\n",
            "epoch: 1, time: 5.283s, loss: 0.379, train accuracy: 0.925\n",
            "epoch: 1, time: 5.783s, loss: 0.263, train accuracy: 0.900\n",
            "epoch: 1, time: 6.339s, loss: 0.380, train accuracy: 0.900\n",
            "epoch: 1, time: 6.708s, loss: 0.188, train accuracy: 0.975\n",
            "epoch: 1, time: 7.080s, loss: 0.487, train accuracy: 0.875\n",
            "epoch: 1, time: 7.465s, loss: 0.249, train accuracy: 0.912\n",
            "epoch: 1, time: 7.839s, loss: 0.237, train accuracy: 0.963\n",
            "epoch: 1, time: 8.219s, loss: 0.258, train accuracy: 0.900\n",
            "epoch: 1, time: 8.603s, loss: 0.328, train accuracy: 0.925\n",
            "epoch: 1, time: 8.987s, loss: 0.400, train accuracy: 0.912\n",
            "epoch: 1, time: 9.364s, loss: 0.330, train accuracy: 0.875\n",
            "epoch: 1, time: 9.756s, loss: 0.309, train accuracy: 0.875\n",
            "epoch: 1, time: 10.139s, loss: 0.368, train accuracy: 0.850\n",
            "epoch: 1, time: 10.527s, loss: 0.516, train accuracy: 0.838\n",
            "epoch: 1, time: 10.908s, loss: 0.331, train accuracy: 0.925\n",
            "epoch: 1, time: 11.282s, loss: 0.170, train accuracy: 0.925\n",
            "epoch: 1, time: 11.679s, loss: 0.232, train accuracy: 0.950\n",
            "epoch: 1, time: 12.064s, loss: 0.238, train accuracy: 0.963\n",
            "epoch: 1, time: 12.442s, loss: 0.263, train accuracy: 0.925\n",
            "epoch: 1, time: 12.830s, loss: 0.385, train accuracy: 0.900\n",
            "epoch: 1, time: 13.213s, loss: 0.215, train accuracy: 0.925\n",
            "epoch: 1, time: 13.601s, loss: 0.328, train accuracy: 0.875\n",
            "epoch: 1, time: 13.987s, loss: 0.240, train accuracy: 0.938\n",
            "epoch: 1, time: 14.365s, loss: 0.254, train accuracy: 0.925\n",
            "epoch: 1, time: 14.760s, loss: 0.244, train accuracy: 0.925\n",
            "epoch: 1, time: 15.151s, loss: 0.122, train accuracy: 0.950\n",
            "epoch: 1, time: 15.524s, loss: 0.068, train accuracy: 1.000\n",
            "epoch: 1, time: 15.919s, loss: 0.272, train accuracy: 0.925\n",
            "epoch: 2, time: 16.111s, loss: 0.205, train accuracy: 0.925\n",
            "epoch: 2, time: 16.605s, loss: 0.074, train accuracy: 0.975\n",
            "epoch: 2, time: 17.106s, loss: 0.187, train accuracy: 0.950\n",
            "epoch: 2, time: 17.584s, loss: 0.178, train accuracy: 0.950\n",
            "epoch: 2, time: 18.166s, loss: 0.119, train accuracy: 0.963\n",
            "epoch: 2, time: 18.606s, loss: 0.186, train accuracy: 0.900\n",
            "epoch: 2, time: 19.001s, loss: 0.226, train accuracy: 0.925\n",
            "epoch: 2, time: 19.437s, loss: 0.125, train accuracy: 0.950\n",
            "epoch: 2, time: 19.833s, loss: 0.274, train accuracy: 0.925\n",
            "epoch: 2, time: 20.219s, loss: 0.132, train accuracy: 0.963\n",
            "epoch: 2, time: 20.602s, loss: 0.362, train accuracy: 0.863\n",
            "epoch: 2, time: 21.018s, loss: 0.109, train accuracy: 0.975\n",
            "epoch: 2, time: 21.413s, loss: 0.206, train accuracy: 0.912\n",
            "epoch: 2, time: 21.836s, loss: 0.134, train accuracy: 0.963\n",
            "epoch: 2, time: 22.229s, loss: 0.081, train accuracy: 0.975\n",
            "epoch: 2, time: 22.619s, loss: 0.173, train accuracy: 0.938\n",
            "epoch: 2, time: 23.026s, loss: 0.168, train accuracy: 0.950\n",
            "epoch: 2, time: 23.405s, loss: 0.256, train accuracy: 0.938\n",
            "epoch: 2, time: 23.795s, loss: 0.084, train accuracy: 0.988\n",
            "epoch: 2, time: 24.194s, loss: 0.179, train accuracy: 0.950\n",
            "epoch: 2, time: 24.575s, loss: 0.093, train accuracy: 0.963\n",
            "epoch: 2, time: 24.966s, loss: 0.181, train accuracy: 0.963\n",
            "epoch: 2, time: 25.339s, loss: 0.078, train accuracy: 0.975\n",
            "epoch: 2, time: 25.707s, loss: 0.134, train accuracy: 0.963\n",
            "epoch: 2, time: 26.097s, loss: 0.143, train accuracy: 0.975\n",
            "epoch: 2, time: 26.502s, loss: 0.208, train accuracy: 0.925\n",
            "epoch: 2, time: 26.884s, loss: 0.075, train accuracy: 0.988\n",
            "epoch: 2, time: 27.273s, loss: 0.087, train accuracy: 0.975\n",
            "epoch: 2, time: 27.645s, loss: 0.138, train accuracy: 0.963\n",
            "epoch: 2, time: 28.043s, loss: 0.074, train accuracy: 0.975\n",
            "epoch: 2, time: 28.512s, loss: 0.129, train accuracy: 0.963\n",
            "epoch: 2, time: 29.008s, loss: 0.088, train accuracy: 0.975\n",
            "epoch: 2, time: 29.491s, loss: 0.088, train accuracy: 0.975\n",
            "epoch: 2, time: 30.031s, loss: 0.150, train accuracy: 0.925\n",
            "epoch: 2, time: 30.512s, loss: 0.181, train accuracy: 0.963\n",
            "epoch: 2, time: 30.897s, loss: 0.173, train accuracy: 0.963\n",
            "epoch: 2, time: 31.299s, loss: 0.271, train accuracy: 0.887\n",
            "epoch: 2, time: 31.683s, loss: 0.182, train accuracy: 0.963\n",
            "epoch: 3, time: 31.880s, loss: 0.050, train accuracy: 1.000\n",
            "epoch: 3, time: 32.271s, loss: 0.182, train accuracy: 0.938\n",
            "epoch: 3, time: 32.663s, loss: 0.216, train accuracy: 0.925\n",
            "epoch: 3, time: 33.048s, loss: 0.066, train accuracy: 0.988\n",
            "epoch: 3, time: 33.443s, loss: 0.166, train accuracy: 0.950\n",
            "epoch: 3, time: 33.812s, loss: 0.082, train accuracy: 0.975\n",
            "epoch: 3, time: 34.187s, loss: 0.087, train accuracy: 0.963\n",
            "epoch: 3, time: 34.579s, loss: 0.071, train accuracy: 0.988\n",
            "epoch: 3, time: 34.967s, loss: 0.088, train accuracy: 0.988\n",
            "epoch: 3, time: 35.361s, loss: 0.108, train accuracy: 0.963\n",
            "epoch: 3, time: 35.738s, loss: 0.051, train accuracy: 0.988\n",
            "epoch: 3, time: 36.125s, loss: 0.106, train accuracy: 0.988\n",
            "epoch: 3, time: 36.527s, loss: 0.096, train accuracy: 0.975\n",
            "epoch: 3, time: 36.934s, loss: 0.151, train accuracy: 0.963\n",
            "epoch: 3, time: 37.311s, loss: 0.167, train accuracy: 0.950\n",
            "epoch: 3, time: 37.698s, loss: 0.084, train accuracy: 0.975\n",
            "epoch: 3, time: 38.081s, loss: 0.161, train accuracy: 0.975\n",
            "epoch: 3, time: 38.474s, loss: 0.068, train accuracy: 0.975\n",
            "epoch: 3, time: 38.859s, loss: 0.092, train accuracy: 0.975\n",
            "epoch: 3, time: 39.249s, loss: 0.086, train accuracy: 0.950\n",
            "epoch: 3, time: 39.646s, loss: 0.141, train accuracy: 0.950\n",
            "epoch: 3, time: 40.030s, loss: 0.083, train accuracy: 0.975\n",
            "epoch: 3, time: 40.489s, loss: 0.164, train accuracy: 0.950\n",
            "epoch: 3, time: 40.998s, loss: 0.037, train accuracy: 1.000\n",
            "epoch: 3, time: 41.490s, loss: 0.067, train accuracy: 0.975\n",
            "epoch: 3, time: 42.028s, loss: 0.094, train accuracy: 0.950\n",
            "epoch: 3, time: 42.520s, loss: 0.127, train accuracy: 0.963\n",
            "epoch: 3, time: 42.913s, loss: 0.223, train accuracy: 0.963\n",
            "epoch: 3, time: 43.285s, loss: 0.092, train accuracy: 0.975\n",
            "epoch: 3, time: 43.674s, loss: 0.098, train accuracy: 0.963\n",
            "epoch: 3, time: 44.057s, loss: 0.040, train accuracy: 0.988\n",
            "epoch: 3, time: 44.438s, loss: 0.079, train accuracy: 0.963\n",
            "epoch: 3, time: 44.827s, loss: 0.087, train accuracy: 0.963\n",
            "epoch: 3, time: 45.209s, loss: 0.137, train accuracy: 0.950\n",
            "epoch: 3, time: 45.587s, loss: 0.061, train accuracy: 0.988\n",
            "epoch: 3, time: 45.980s, loss: 0.102, train accuracy: 0.975\n",
            "epoch: 3, time: 46.354s, loss: 0.059, train accuracy: 0.988\n",
            "epoch: 3, time: 46.743s, loss: 0.135, train accuracy: 0.950\n",
            "epoch: 4, time: 46.936s, loss: 0.073, train accuracy: 0.963\n",
            "epoch: 4, time: 47.306s, loss: 0.120, train accuracy: 0.975\n",
            "epoch: 4, time: 47.692s, loss: 0.065, train accuracy: 0.988\n",
            "epoch: 4, time: 48.089s, loss: 0.228, train accuracy: 0.925\n",
            "epoch: 4, time: 48.465s, loss: 0.053, train accuracy: 1.000\n",
            "epoch: 4, time: 48.852s, loss: 0.071, train accuracy: 0.975\n",
            "epoch: 4, time: 49.230s, loss: 0.061, train accuracy: 0.988\n",
            "epoch: 4, time: 49.612s, loss: 0.238, train accuracy: 0.912\n",
            "epoch: 4, time: 50.004s, loss: 0.094, train accuracy: 0.975\n",
            "epoch: 4, time: 50.380s, loss: 0.038, train accuracy: 0.988\n",
            "epoch: 4, time: 50.769s, loss: 0.128, train accuracy: 0.988\n",
            "epoch: 4, time: 51.161s, loss: 0.072, train accuracy: 0.988\n",
            "epoch: 4, time: 51.543s, loss: 0.023, train accuracy: 1.000\n",
            "epoch: 4, time: 51.938s, loss: 0.114, train accuracy: 0.975\n",
            "epoch: 4, time: 52.340s, loss: 0.084, train accuracy: 0.988\n",
            "epoch: 4, time: 52.907s, loss: 0.047, train accuracy: 1.000\n",
            "epoch: 4, time: 53.389s, loss: 0.059, train accuracy: 0.988\n",
            "epoch: 4, time: 53.893s, loss: 0.027, train accuracy: 1.000\n",
            "epoch: 4, time: 54.435s, loss: 0.126, train accuracy: 0.950\n",
            "epoch: 4, time: 54.813s, loss: 0.060, train accuracy: 0.988\n",
            "epoch: 4, time: 55.203s, loss: 0.154, train accuracy: 0.963\n",
            "epoch: 4, time: 55.579s, loss: 0.072, train accuracy: 0.988\n",
            "epoch: 4, time: 55.961s, loss: 0.132, train accuracy: 0.975\n",
            "epoch: 4, time: 56.351s, loss: 0.050, train accuracy: 0.988\n",
            "epoch: 4, time: 56.757s, loss: 0.108, train accuracy: 0.950\n",
            "epoch: 4, time: 57.151s, loss: 0.071, train accuracy: 0.988\n",
            "epoch: 4, time: 57.526s, loss: 0.117, train accuracy: 0.975\n",
            "epoch: 4, time: 57.903s, loss: 0.062, train accuracy: 0.975\n",
            "epoch: 4, time: 58.289s, loss: 0.247, train accuracy: 0.912\n",
            "epoch: 4, time: 58.667s, loss: 0.081, train accuracy: 0.988\n",
            "epoch: 4, time: 59.046s, loss: 0.097, train accuracy: 0.975\n",
            "epoch: 4, time: 59.432s, loss: 0.051, train accuracy: 0.988\n",
            "epoch: 4, time: 59.803s, loss: 0.094, train accuracy: 0.963\n",
            "epoch: 4, time: 60.194s, loss: 0.065, train accuracy: 0.975\n",
            "epoch: 4, time: 60.568s, loss: 0.116, train accuracy: 0.975\n",
            "epoch: 4, time: 60.947s, loss: 0.171, train accuracy: 0.963\n",
            "epoch: 4, time: 61.346s, loss: 0.079, train accuracy: 0.975\n",
            "epoch: 4, time: 61.715s, loss: 0.073, train accuracy: 0.988\n",
            "epoch: 5, time: 61.909s, loss: 0.143, train accuracy: 0.950\n",
            "epoch: 5, time: 62.293s, loss: 0.025, train accuracy: 1.000\n",
            "epoch: 5, time: 62.682s, loss: 0.116, train accuracy: 0.988\n",
            "epoch: 5, time: 63.062s, loss: 0.080, train accuracy: 0.963\n",
            "epoch: 5, time: 63.450s, loss: 0.026, train accuracy: 1.000\n",
            "epoch: 5, time: 63.832s, loss: 0.042, train accuracy: 0.988\n",
            "epoch: 5, time: 64.221s, loss: 0.026, train accuracy: 0.988\n",
            "epoch: 5, time: 64.723s, loss: 0.040, train accuracy: 1.000\n",
            "epoch: 5, time: 65.206s, loss: 0.090, train accuracy: 0.963\n",
            "epoch: 5, time: 65.685s, loss: 0.142, train accuracy: 0.975\n",
            "epoch: 5, time: 66.246s, loss: 0.053, train accuracy: 0.988\n",
            "epoch: 5, time: 66.662s, loss: 0.063, train accuracy: 0.975\n",
            "epoch: 5, time: 67.044s, loss: 0.096, train accuracy: 0.963\n",
            "epoch: 5, time: 67.417s, loss: 0.033, train accuracy: 1.000\n",
            "epoch: 5, time: 67.804s, loss: 0.058, train accuracy: 0.988\n",
            "epoch: 5, time: 68.181s, loss: 0.124, train accuracy: 0.975\n",
            "epoch: 5, time: 68.571s, loss: 0.072, train accuracy: 0.988\n",
            "epoch: 5, time: 68.951s, loss: 0.021, train accuracy: 1.000\n",
            "epoch: 5, time: 69.341s, loss: 0.199, train accuracy: 0.950\n",
            "epoch: 5, time: 69.741s, loss: 0.030, train accuracy: 1.000\n",
            "epoch: 5, time: 70.121s, loss: 0.031, train accuracy: 0.988\n",
            "epoch: 5, time: 70.497s, loss: 0.024, train accuracy: 1.000\n",
            "epoch: 5, time: 70.892s, loss: 0.039, train accuracy: 0.988\n",
            "epoch: 5, time: 71.262s, loss: 0.083, train accuracy: 0.963\n",
            "epoch: 5, time: 71.655s, loss: 0.008, train accuracy: 1.000\n",
            "epoch: 5, time: 72.039s, loss: 0.036, train accuracy: 0.988\n",
            "epoch: 5, time: 72.422s, loss: 0.026, train accuracy: 0.988\n",
            "epoch: 5, time: 72.833s, loss: 0.046, train accuracy: 0.988\n",
            "epoch: 5, time: 73.214s, loss: 0.094, train accuracy: 0.963\n",
            "epoch: 5, time: 73.587s, loss: 0.092, train accuracy: 0.975\n",
            "epoch: 5, time: 73.982s, loss: 0.044, train accuracy: 0.975\n",
            "epoch: 5, time: 74.354s, loss: 0.052, train accuracy: 0.988\n",
            "epoch: 5, time: 74.759s, loss: 0.047, train accuracy: 0.988\n",
            "epoch: 5, time: 75.163s, loss: 0.012, train accuracy: 1.000\n",
            "epoch: 5, time: 75.556s, loss: 0.051, train accuracy: 0.975\n",
            "epoch: 5, time: 75.953s, loss: 0.098, train accuracy: 0.963\n",
            "epoch: 5, time: 76.353s, loss: 0.017, train accuracy: 1.000\n",
            "epoch: 5, time: 76.908s, loss: 0.143, train accuracy: 0.950\n",
            "epoch: 6, time: 77.158s, loss: 0.072, train accuracy: 0.963\n",
            "epoch: 6, time: 77.636s, loss: 0.304, train accuracy: 0.938\n",
            "epoch: 6, time: 78.214s, loss: 0.021, train accuracy: 1.000\n",
            "epoch: 6, time: 78.644s, loss: 0.060, train accuracy: 0.975\n",
            "epoch: 6, time: 79.038s, loss: 0.023, train accuracy: 0.988\n",
            "epoch: 6, time: 79.411s, loss: 0.040, train accuracy: 0.975\n",
            "epoch: 6, time: 79.788s, loss: 0.057, train accuracy: 0.975\n",
            "epoch: 6, time: 80.177s, loss: 0.094, train accuracy: 0.963\n",
            "epoch: 6, time: 80.556s, loss: 0.118, train accuracy: 0.975\n",
            "epoch: 6, time: 80.959s, loss: 0.152, train accuracy: 0.950\n",
            "epoch: 6, time: 81.342s, loss: 0.079, train accuracy: 0.963\n",
            "epoch: 6, time: 81.749s, loss: 0.168, train accuracy: 0.963\n",
            "epoch: 6, time: 82.196s, loss: 0.115, train accuracy: 0.975\n",
            "epoch: 6, time: 82.594s, loss: 0.083, train accuracy: 0.975\n",
            "epoch: 6, time: 83.014s, loss: 0.197, train accuracy: 0.950\n",
            "epoch: 6, time: 83.398s, loss: 0.063, train accuracy: 0.963\n",
            "epoch: 6, time: 83.774s, loss: 0.030, train accuracy: 1.000\n",
            "epoch: 6, time: 84.166s, loss: 0.075, train accuracy: 0.975\n",
            "epoch: 6, time: 84.547s, loss: 0.030, train accuracy: 0.988\n",
            "epoch: 6, time: 84.933s, loss: 0.093, train accuracy: 0.975\n",
            "epoch: 6, time: 85.319s, loss: 0.112, train accuracy: 0.975\n",
            "epoch: 6, time: 85.702s, loss: 0.095, train accuracy: 0.963\n",
            "epoch: 6, time: 86.094s, loss: 0.057, train accuracy: 0.988\n",
            "epoch: 6, time: 86.471s, loss: 0.080, train accuracy: 0.975\n",
            "epoch: 6, time: 86.869s, loss: 0.018, train accuracy: 1.000\n",
            "epoch: 6, time: 87.260s, loss: 0.143, train accuracy: 0.963\n",
            "epoch: 6, time: 87.644s, loss: 0.018, train accuracy: 0.988\n",
            "epoch: 6, time: 88.026s, loss: 0.189, train accuracy: 0.963\n",
            "epoch: 6, time: 88.465s, loss: 0.056, train accuracy: 0.988\n",
            "epoch: 6, time: 88.969s, loss: 0.022, train accuracy: 1.000\n",
            "epoch: 6, time: 89.449s, loss: 0.048, train accuracy: 0.975\n",
            "epoch: 6, time: 89.956s, loss: 0.083, train accuracy: 0.975\n",
            "epoch: 6, time: 90.476s, loss: 0.063, train accuracy: 0.988\n",
            "epoch: 6, time: 90.856s, loss: 0.075, train accuracy: 0.963\n",
            "epoch: 6, time: 91.265s, loss: 0.090, train accuracy: 0.963\n",
            "epoch: 6, time: 91.642s, loss: 0.064, train accuracy: 0.988\n",
            "epoch: 6, time: 92.022s, loss: 0.088, train accuracy: 0.975\n",
            "epoch: 6, time: 92.418s, loss: 0.049, train accuracy: 0.975\n",
            "epoch: 7, time: 92.611s, loss: 0.037, train accuracy: 0.988\n",
            "epoch: 7, time: 92.985s, loss: 0.072, train accuracy: 0.988\n",
            "epoch: 7, time: 93.380s, loss: 0.061, train accuracy: 0.975\n",
            "epoch: 7, time: 93.754s, loss: 0.071, train accuracy: 0.975\n",
            "epoch: 7, time: 94.132s, loss: 0.093, train accuracy: 0.950\n",
            "epoch: 7, time: 94.517s, loss: 0.035, train accuracy: 1.000\n",
            "epoch: 7, time: 94.896s, loss: 0.021, train accuracy: 0.988\n",
            "epoch: 7, time: 95.269s, loss: 0.024, train accuracy: 0.988\n",
            "epoch: 7, time: 95.661s, loss: 0.168, train accuracy: 0.963\n",
            "epoch: 7, time: 96.041s, loss: 0.025, train accuracy: 1.000\n",
            "epoch: 7, time: 96.425s, loss: 0.074, train accuracy: 0.988\n",
            "epoch: 7, time: 96.799s, loss: 0.032, train accuracy: 0.988\n",
            "epoch: 7, time: 97.174s, loss: 0.038, train accuracy: 0.975\n",
            "epoch: 7, time: 97.557s, loss: 0.027, train accuracy: 1.000\n",
            "epoch: 7, time: 97.929s, loss: 0.006, train accuracy: 1.000\n",
            "epoch: 7, time: 98.307s, loss: 0.066, train accuracy: 0.988\n",
            "epoch: 7, time: 98.690s, loss: 0.080, train accuracy: 0.963\n",
            "epoch: 7, time: 99.064s, loss: 0.019, train accuracy: 1.000\n",
            "epoch: 7, time: 99.435s, loss: 0.126, train accuracy: 0.963\n",
            "epoch: 7, time: 99.825s, loss: 0.125, train accuracy: 0.963\n",
            "epoch: 7, time: 100.200s, loss: 0.102, train accuracy: 0.975\n",
            "epoch: 7, time: 100.700s, loss: 0.030, train accuracy: 1.000\n",
            "epoch: 7, time: 101.174s, loss: 0.027, train accuracy: 1.000\n",
            "epoch: 7, time: 101.667s, loss: 0.119, train accuracy: 0.988\n",
            "epoch: 7, time: 102.240s, loss: 0.016, train accuracy: 1.000\n",
            "epoch: 7, time: 102.681s, loss: 0.023, train accuracy: 1.000\n",
            "epoch: 7, time: 103.061s, loss: 0.058, train accuracy: 0.975\n",
            "epoch: 7, time: 103.441s, loss: 0.056, train accuracy: 0.975\n",
            "epoch: 7, time: 103.830s, loss: 0.094, train accuracy: 0.975\n",
            "epoch: 7, time: 104.209s, loss: 0.040, train accuracy: 0.988\n",
            "epoch: 7, time: 104.582s, loss: 0.077, train accuracy: 0.975\n",
            "epoch: 7, time: 104.985s, loss: 0.053, train accuracy: 0.975\n",
            "epoch: 7, time: 105.362s, loss: 0.009, train accuracy: 1.000\n",
            "epoch: 7, time: 105.757s, loss: 0.049, train accuracy: 0.988\n",
            "epoch: 7, time: 106.139s, loss: 0.022, train accuracy: 0.988\n",
            "epoch: 7, time: 106.514s, loss: 0.046, train accuracy: 0.988\n",
            "epoch: 7, time: 106.909s, loss: 0.078, train accuracy: 0.988\n",
            "epoch: 7, time: 107.284s, loss: 0.044, train accuracy: 0.988\n",
            "epoch: 8, time: 107.474s, loss: 0.017, train accuracy: 1.000\n",
            "epoch: 8, time: 107.873s, loss: 0.043, train accuracy: 0.988\n",
            "epoch: 8, time: 108.249s, loss: 0.057, train accuracy: 0.975\n",
            "epoch: 8, time: 108.627s, loss: 0.043, train accuracy: 0.988\n",
            "epoch: 8, time: 109.017s, loss: 0.075, train accuracy: 0.975\n",
            "epoch: 8, time: 109.388s, loss: 0.017, train accuracy: 1.000\n",
            "epoch: 8, time: 109.761s, loss: 0.019, train accuracy: 1.000\n",
            "epoch: 8, time: 110.150s, loss: 0.092, train accuracy: 0.975\n",
            "epoch: 8, time: 110.528s, loss: 0.036, train accuracy: 1.000\n",
            "epoch: 8, time: 110.930s, loss: 0.018, train accuracy: 1.000\n",
            "epoch: 8, time: 111.312s, loss: 0.125, train accuracy: 0.963\n",
            "epoch: 8, time: 111.693s, loss: 0.068, train accuracy: 0.975\n",
            "epoch: 8, time: 112.081s, loss: 0.076, train accuracy: 0.975\n",
            "epoch: 8, time: 112.512s, loss: 0.037, train accuracy: 0.988\n",
            "epoch: 8, time: 113.032s, loss: 0.081, train accuracy: 0.988\n",
            "epoch: 8, time: 113.509s, loss: 0.055, train accuracy: 0.988\n",
            "epoch: 8, time: 114.049s, loss: 0.050, train accuracy: 0.975\n",
            "epoch: 8, time: 114.564s, loss: 0.025, train accuracy: 1.000\n",
            "epoch: 8, time: 114.946s, loss: 0.015, train accuracy: 1.000\n",
            "epoch: 8, time: 115.332s, loss: 0.059, train accuracy: 0.988\n",
            "epoch: 8, time: 115.722s, loss: 0.039, train accuracy: 0.975\n",
            "epoch: 8, time: 116.110s, loss: 0.101, train accuracy: 0.975\n",
            "epoch: 8, time: 116.497s, loss: 0.090, train accuracy: 0.963\n",
            "epoch: 8, time: 116.903s, loss: 0.067, train accuracy: 0.975\n",
            "epoch: 8, time: 117.288s, loss: 0.067, train accuracy: 0.975\n",
            "epoch: 8, time: 117.664s, loss: 0.039, train accuracy: 0.975\n",
            "epoch: 8, time: 118.046s, loss: 0.040, train accuracy: 0.975\n",
            "epoch: 8, time: 118.437s, loss: 0.037, train accuracy: 0.988\n",
            "epoch: 8, time: 118.817s, loss: 0.035, train accuracy: 0.988\n",
            "epoch: 8, time: 119.195s, loss: 0.023, train accuracy: 1.000\n",
            "epoch: 8, time: 119.578s, loss: 0.030, train accuracy: 0.975\n",
            "epoch: 8, time: 119.959s, loss: 0.032, train accuracy: 0.988\n",
            "epoch: 8, time: 120.347s, loss: 0.014, train accuracy: 1.000\n",
            "epoch: 8, time: 120.738s, loss: 0.079, train accuracy: 0.988\n",
            "epoch: 8, time: 121.129s, loss: 0.037, train accuracy: 0.988\n",
            "epoch: 8, time: 121.520s, loss: 0.015, train accuracy: 1.000\n",
            "epoch: 8, time: 121.972s, loss: 0.068, train accuracy: 0.963\n",
            "epoch: 8, time: 122.361s, loss: 0.053, train accuracy: 0.988\n",
            "epoch: 9, time: 122.553s, loss: 0.167, train accuracy: 0.975\n",
            "epoch: 9, time: 122.932s, loss: 0.035, train accuracy: 1.000\n",
            "epoch: 9, time: 123.302s, loss: 0.039, train accuracy: 0.975\n",
            "epoch: 9, time: 123.693s, loss: 0.050, train accuracy: 0.975\n",
            "epoch: 9, time: 124.084s, loss: 0.075, train accuracy: 0.963\n",
            "epoch: 9, time: 124.516s, loss: 0.067, train accuracy: 0.988\n",
            "epoch: 9, time: 125.007s, loss: 0.037, train accuracy: 1.000\n",
            "epoch: 9, time: 125.484s, loss: 0.070, train accuracy: 0.975\n",
            "epoch: 9, time: 125.986s, loss: 0.038, train accuracy: 0.975\n",
            "epoch: 9, time: 126.514s, loss: 0.058, train accuracy: 0.963\n",
            "epoch: 9, time: 126.894s, loss: 0.213, train accuracy: 0.950\n",
            "epoch: 9, time: 127.263s, loss: 0.069, train accuracy: 0.988\n",
            "epoch: 9, time: 127.646s, loss: 0.021, train accuracy: 1.000\n",
            "epoch: 9, time: 128.023s, loss: 0.126, train accuracy: 0.975\n",
            "epoch: 9, time: 128.396s, loss: 0.027, train accuracy: 1.000\n",
            "epoch: 9, time: 128.784s, loss: 0.067, train accuracy: 0.988\n",
            "epoch: 9, time: 129.162s, loss: 0.196, train accuracy: 0.950\n",
            "epoch: 9, time: 129.531s, loss: 0.036, train accuracy: 0.975\n",
            "epoch: 9, time: 129.922s, loss: 0.020, train accuracy: 0.988\n",
            "epoch: 9, time: 130.296s, loss: 0.021, train accuracy: 1.000\n",
            "epoch: 9, time: 130.682s, loss: 0.075, train accuracy: 0.963\n",
            "epoch: 9, time: 131.065s, loss: 0.038, train accuracy: 0.988\n",
            "epoch: 9, time: 131.436s, loss: 0.065, train accuracy: 0.988\n",
            "epoch: 9, time: 131.823s, loss: 0.084, train accuracy: 0.975\n",
            "epoch: 9, time: 132.196s, loss: 0.020, train accuracy: 0.988\n",
            "epoch: 9, time: 132.571s, loss: 0.052, train accuracy: 0.988\n",
            "epoch: 9, time: 132.970s, loss: 0.024, train accuracy: 1.000\n",
            "epoch: 9, time: 133.341s, loss: 0.017, train accuracy: 1.000\n",
            "epoch: 9, time: 133.730s, loss: 0.026, train accuracy: 1.000\n",
            "epoch: 9, time: 134.115s, loss: 0.084, train accuracy: 0.963\n",
            "epoch: 9, time: 134.494s, loss: 0.056, train accuracy: 0.988\n",
            "epoch: 9, time: 134.903s, loss: 0.125, train accuracy: 0.925\n",
            "epoch: 9, time: 135.297s, loss: 0.011, train accuracy: 1.000\n",
            "epoch: 9, time: 135.695s, loss: 0.014, train accuracy: 1.000\n",
            "epoch: 9, time: 136.105s, loss: 0.037, train accuracy: 0.988\n",
            "epoch: 9, time: 136.550s, loss: 0.037, train accuracy: 0.988\n",
            "epoch: 9, time: 137.068s, loss: 0.041, train accuracy: 0.988\n",
            "epoch: 9, time: 137.545s, loss: 0.034, train accuracy: 0.988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Uc1816EHVQY"
      },
      "source": [
        "### Evaluate the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hItOOXuwCD0w",
        "outputId": "9dcb2c85-c79e-4490-bf20-bac777c7c280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct_total = 0\n",
        "\n",
        "for i, (x_batch, y_batch) in enumerate(testloader):\n",
        "  x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
        "\n",
        "  y_pred = net(x_batch)\n",
        "  y_pred_max = torch.argmax(y_pred, dim=1)\n",
        "\n",
        "  correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n",
        "\n",
        "print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 0.981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61nCgln8HZaN"
      },
      "source": [
        "### Show the model's prediction for a random sample from the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2grnY_u2-O2",
        "outputId": "0dc5dbda-d1b8-497b-fa6a-bd9ef364d157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        }
      },
      "source": [
        "# choose a picture at random\n",
        "im_minibatch, label_minibatch = next(iter(testloader))\n",
        "im, label = im_minibatch[0].cpu(), label_minibatch[0].cpu()\n",
        "\n",
        "# diplay the picture\n",
        "show(im.squeeze())\n",
        "\n",
        "# feed it to the net and display the confidence scores\n",
        "prob = F.softmax(net.cpu()(im.unsqueeze(0)), dim=1)\n",
        "\n",
        "print('Confidence scores:\\n' + '\\n'.join(['{}: {}'.format(i, p.item()) for i, p in enumerate(prob.squeeze())]))\n",
        "\n",
        "print('\\nLabel with highest confidence score: {}'.format(torch.argmax(prob).item()))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence scores:\n",
            "0: 3.6136904579819884e-10\n",
            "1: 7.347520813993924e-09\n",
            "2: 8.656170225052051e-10\n",
            "3: 4.740766144095687e-06\n",
            "4: 6.940841558389366e-05\n",
            "5: 3.174843641318148e-07\n",
            "6: 3.639633299606926e-12\n",
            "7: 0.0002999534481205046\n",
            "8: 3.2456462122354424e-06\n",
            "9: 0.9996223449707031\n",
            "\n",
            "Label with highest confidence score: 9\n"
          ]
        }
      ]
    }
  ]
}