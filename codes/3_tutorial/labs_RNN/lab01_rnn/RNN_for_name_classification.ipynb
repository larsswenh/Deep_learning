{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C20DXlMOAi9"
      },
      "source": [
        "# Classifying names with a character-level RNN\n",
        "In this notebook we will use a recurrent neural network to predict the language from which certain surnames originate. When given some surname the network outputs a probability distribution over 18 possible languages corresponding to the likelyhood that they originate from these languages.\n",
        "\n",
        "This exercise was taken from the [PyTorch website](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4t1dQLLZDKc"
      },
      "source": [
        "### Download the dataset\n",
        "The dataset that is used can be downloaded [here](https://download.pytorch.org/tutorial/data.zip). Extract it to the directory where this notebook is located.\n",
        "Included in the ``data/names`` directory are 18 text files named as\n",
        "\"[Language].txt\". Each file contains a bunch of names, one name per\n",
        "line, mostly romanized (but we still need to convert from Unicode to\n",
        "ASCII)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNu_cHzjcUk8"
      },
      "source": [
        "If you are running this notebook on Colab you can access the dataset by storing it on your Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eo3dBmNZcQZr",
        "outputId": "7a77058b-d208-4555-869a-e0974c9b47c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPJHoYlkdot3"
      },
      "source": [
        "**Change the following path variable such that it points to the location of the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GdI9hWoEd6xi",
        "outputId": "b3ca5737-826e-4ff9-d01a-b75e52095b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Irish.txt',\n",
              " 'Dutch.txt',\n",
              " 'Japanese.txt',\n",
              " 'Polish.txt',\n",
              " 'Arabic.txt',\n",
              " 'Korean.txt',\n",
              " 'Portuguese.txt',\n",
              " 'Russian.txt',\n",
              " 'French.txt',\n",
              " 'Spanish.txt',\n",
              " 'Vietnamese.txt',\n",
              " 'Chinese.txt',\n",
              " 'Italian.txt',\n",
              " 'Czech.txt',\n",
              " 'Greek.txt',\n",
              " 'German.txt',\n",
              " 'Scottish.txt',\n",
              " 'English.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "path_to_data = './gdrive/My Drive/data'  # TODO -- set this to the right location!\n",
        "\n",
        "os.listdir(path_to_data + '/data/names/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTyw5SkeXVxu"
      },
      "source": [
        "### Preparing the data\n",
        "We first preprocess the dataset by limiting ourselves to ASCII characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6Ztn7HClez8U",
        "outputId": "231da67f-aeed-4dd3-daf9-429eca9a5fba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slusarski\n"
          ]
        }
      ],
      "source": [
        "import unicodedata\n",
        "import string\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "print(unicodeToAscii('Ślusàrski'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8daKzr0eg7LT"
      },
      "outputs": [],
      "source": [
        "# Build a dictionary containing a list of names for each language\n",
        "names_per_language = dict()\n",
        "languages = list()  # Keep a list containing all languages\n",
        "\n",
        "def readNames(file_path):  # Define a function that reads all names from some file in /data/names/ and converts them to ASCII\n",
        "  with open(file_path, encoding='utf-8') as f:\n",
        "    unicode_names = f.read().strip().split('\\n')  # Split the file on new lines. Each line contains a name (in unicode)\n",
        "    return [unicodeToAscii(name) for name in unicode_names]  # Convert all names to ASCII\n",
        "\n",
        "# For all files in /data/names/ read the names. Group the names by the language they are in\n",
        "\n",
        "for filename in os.listdir(path_to_data + '/data/names/'):\n",
        "  language, _ = filename.split('.')  # Remove the file extention to obtain the class label (the language)\n",
        "  languages.append(language)\n",
        "  names = readNames(path_to_data + '/data/names/' + filename)  # Read the names in the current file\n",
        "  names_per_language[language] = names\n",
        "\n",
        "n_languages = len(languages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYL9BPerj2BB"
      },
      "source": [
        "Now we have ``names_per_language``, a dictionary mapping each language to a list of names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QHOPEma4j2Jj",
        "outputId": "081cc4ed-91d1-4adc-d004-016ebc9a648b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
          ]
        }
      ],
      "source": [
        "print(names_per_language['Italian'][:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrO3p0ciXdDh"
      },
      "source": [
        "### Exercise - Transforming names into suitable inputs\n",
        "\n",
        "Now that we have all the names organized, we need to turn them into\n",
        "Tensors to make any use of them.\n",
        "\n",
        "To represent a single letter, we use a \"one-hot vector\" of size\n",
        "``<1 x n_letters>``. A one-hot vector is filled with 0s except for a 1\n",
        "at index of the current letter, e.g. ``\"b\" = <0 1 0 0 0 ...>``.\n",
        "\n",
        "To make a word we join a bunch of those into a 2D matrix\n",
        "``<line_length x 1 x n_letters>``.\n",
        "\n",
        "That extra 1 dimension is because PyTorch assumes everything is in\n",
        "batches - we're just using a batch size of 1 here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Z8e9Kdxpl6sS",
        "outputId": "e30bd04b-f4b3-4c23-e2ec-78fbee0c6d14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0.]])\n",
            "torch.Size([5, 1, 57])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Find letter index from all_letters, e.g. \"a\" = 0\n",
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter)\n",
        "\n",
        "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
        "def letterToTensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters)\n",
        "    tensor[0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "# Turn a line into a <line_length x 1 x n_letters>,\n",
        "# or an array of one-hot letter vectors\n",
        "def lineToTensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "print(letterToTensor('J'))\n",
        "\n",
        "print(lineToTensor('Jones').size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3PZ8LZlXiur"
      },
      "source": [
        "### Exercise - Define a RNN architecture\n",
        "\n",
        "Create a neural network that takes as input some encoding of a character as well as a hidden state tensor. These two tensors are concatenated and passed to the following:\n",
        "* a linear layer that produces the next hidden state tensor (no activation function)\n",
        "* a linear layer that produces an output tensor (no activation function)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "02jJFESsnA3W"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "\n",
        "        hidden = self.i2h(combined)\n",
        "        output = self.i2o(combined)\n",
        "\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        "n_hidden = 128\n",
        "rnn = RNN(n_letters, n_hidden, n_languages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWuIJQnJ9NRn"
      },
      "source": [
        "To run a step of this network we need to pass an input (in our case, the\n",
        "Tensor for the current letter) and a previous hidden state (which we\n",
        "initialize as zeros at first). We'll get back the output and a next hidden state (which we keep for the next\n",
        "step).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jts3zvXo7mSD",
        "outputId": "20d204ff-53fd-4354-c17a-fb47cc2c4a01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 1, 57])\n",
            "torch.Size([1, 57])\n",
            "torch.Size([1, 128])\n",
            "tensor([[0.0540, 0.0569, 0.0544, 0.0554, 0.0558, 0.0517, 0.0583, 0.0570, 0.0513,\n",
            "         0.0531, 0.0549, 0.0583, 0.0593, 0.0626, 0.0570, 0.0555, 0.0532, 0.0513]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "input_tensor = lineToTensor('Albert')\n",
        "hidden = torch.zeros(1, n_hidden)  # Initialize the hidden state as zeros\n",
        "\n",
        "print(input_tensor.shape)  # The name contains 6 characters which are all encoded as 1-hot vectors of length 57 (corresponding to all possible input characters)\n",
        "print(input_tensor[0].shape)  # Show the shape of a single character. The 1 is the batch dimension. In this example we set the batch size to 1 for simplicity\n",
        "print(hidden.shape)  # Show the shape of the hidden state vector\n",
        "\n",
        "output, next_hidden = rnn(input_tensor[0], hidden)  # Pass the first letter in the name to the network, as well as the initial hidden state\n",
        "\n",
        "print(F.softmax(output, dim=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhR9-5IKXoj2"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pDvQVMhANx2"
      },
      "source": [
        "First we will define a function to sample random data points from the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cMF_KUeH_nNt",
        "outputId": "274bb88a-5828-4373-e5e9-a4a9f4bbf478",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 0, Name: Nghiem, Language: Vietnamese\n",
            "Example 1, Name: Ta, Language: Vietnamese\n",
            "Example 2, Name: Schmied, Language: Czech\n",
            "Example 3, Name: Rosa, Language: Italian\n",
            "Example 4, Name: Landolfi, Language: Italian\n",
            "Example 5, Name: Schoorel, Language: Dutch\n",
            "Example 6, Name: Kunisada, Language: Japanese\n",
            "Example 7, Name: Colbert, Language: French\n",
            "Example 8, Name: Khoury, Language: Arabic\n",
            "Example 9, Name: Corti, Language: Italian\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def random_train_example():\n",
        "  # Select a random name in some random language\n",
        "  language = random.choice(languages)\n",
        "  name = random.choice(names_per_language[language])\n",
        "  # Convert the name to a suitable input tensor\n",
        "  name_tensor = lineToTensor(name)\n",
        "  # Convert the language to a suitable target tensor\n",
        "  lang_tensor = torch.LongTensor([languages.index(language)])  # The tensor datatype is 'long' as it contains an integer corresponding to the index of the language\n",
        "  return language, name, lang_tensor, name_tensor\n",
        "\n",
        "for i in range(10):\n",
        "    language, name, lang_tensor, name_tensor = random_train_example()\n",
        "\n",
        "    print(f'Example {i}, Name: {name}, Language: {language}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzNuGzIVZOZE"
      },
      "source": [
        "Next we define a function that performs stochastic gradient descent using a single data point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GNMfSkKMDF2V"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.005)\n",
        "\n",
        "def train_on_example(name_tensor, language_tensor):\n",
        "  hidden_state = torch.zeros(1, n_hidden)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  for character_tensor in name_tensor:  # Perform a forward pass for each character in the name\n",
        "    out, hidden_state = rnn.forward(character_tensor, hidden_state)\n",
        "\n",
        "  loss = criterion(out, language_tensor)\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  return out, loss.item()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEb04AhsZgYE"
      },
      "source": [
        "Now iterate through the dataset to train the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EdcLFM-VFJMw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c50beb-495b-4755-e94e-af4a6ff44d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1000, Loss: 2.832 Name: Ying             Language: Chinese          Classified as: Korean           Incorrect\n",
            "Example 2000, Loss: 2.797 Name: Cho              Language: Korean           Classified as: Portuguese       Incorrect\n",
            "Example 3000, Loss: 2.798 Name: Yau              Language: Chinese          Classified as: Irish            Incorrect\n",
            "Example 4000, Loss: 2.918 Name: Papageorge       Language: Greek            Classified as: Irish            Incorrect\n",
            "Example 5000, Loss: 2.529 Name: Schenck          Language: Dutch            Classified as: Polish           Incorrect\n",
            "Example 6000, Loss: 1.531 Name: Ran              Language: Chinese          Classified as: Chinese          Correct\n",
            "Example 7000, Loss: 2.210 Name: Omischenko       Language: Russian          Classified as: Polish           Incorrect\n",
            "Example 8000, Loss: 3.163 Name: Fuhrmann         Language: German           Classified as: Irish            Incorrect\n",
            "Example 9000, Loss: 1.996 Name: Nakamura         Language: Japanese         Classified as: Japanese         Correct\n",
            "Example 10000, Loss: 2.152 Name: O'Kane           Language: Irish            Classified as: Japanese         Incorrect\n",
            "Example 11000, Loss: 1.526 Name: Samios           Language: Greek            Classified as: Greek            Correct\n",
            "Example 12000, Loss: 1.209 Name: Toselli          Language: Italian          Classified as: Italian          Correct\n",
            "Example 13000, Loss: 2.859 Name: Alexander        Language: Scottish         Classified as: German           Incorrect\n",
            "Example 14000, Loss: 1.028 Name: Thai             Language: Vietnamese       Classified as: Chinese          Incorrect\n",
            "Example 15000, Loss: 3.235 Name: Koning           Language: Dutch            Classified as: Irish            Incorrect\n",
            "Example 16000, Loss: 2.648 Name: Bell             Language: Scottish         Classified as: German           Incorrect\n",
            "Example 17000, Loss: 0.880 Name: Armonni          Language: Italian          Classified as: Italian          Correct\n",
            "Example 18000, Loss: 2.843 Name: Conway           Language: English          Classified as: Arabic           Incorrect\n",
            "Example 19000, Loss: 0.412 Name: Karahalios       Language: Greek            Classified as: Greek            Correct\n",
            "Example 20000, Loss: 1.859 Name: Kang             Language: Korean           Classified as: Chinese          Incorrect\n",
            "Example 21000, Loss: 3.410 Name: Bove             Language: Italian          Classified as: English          Incorrect\n",
            "Example 22000, Loss: 0.369 Name: Rademakers       Language: Dutch            Classified as: Dutch            Correct\n",
            "Example 23000, Loss: 2.323 Name: Vico             Language: Italian          Classified as: Portuguese       Incorrect\n",
            "Example 24000, Loss: 1.854 Name: Esposito         Language: Italian          Classified as: Japanese         Incorrect\n",
            "Example 25000, Loss: 0.870 Name: Madeira          Language: Portuguese       Classified as: Portuguese       Correct\n",
            "Example 26000, Loss: 1.059 Name: Luo              Language: Chinese          Classified as: Vietnamese       Incorrect\n",
            "Example 27000, Loss: 0.396 Name: Quach            Language: Vietnamese       Classified as: Vietnamese       Correct\n",
            "Example 28000, Loss: 1.544 Name: Henry            Language: English          Classified as: English          Correct\n",
            "Example 29000, Loss: 3.120 Name: Scott            Language: Scottish         Classified as: French           Incorrect\n",
            "Example 30000, Loss: 0.293 Name: Zheltouhov       Language: Russian          Classified as: Russian          Correct\n",
            "Example 31000, Loss: 1.055 Name: Geng             Language: Chinese          Classified as: Chinese          Correct\n",
            "Example 32000, Loss: 1.172 Name: Tsai             Language: Korean           Classified as: Korean           Correct\n",
            "Example 33000, Loss: 0.689 Name: Hong             Language: Chinese          Classified as: Chinese          Correct\n",
            "Example 34000, Loss: 0.991 Name: Said             Language: Arabic           Classified as: Arabic           Correct\n",
            "Example 35000, Loss: 1.150 Name: Osaragi          Language: Japanese         Classified as: Japanese         Correct\n",
            "Example 36000, Loss: 4.155 Name: King             Language: Scottish         Classified as: Chinese          Incorrect\n",
            "Example 37000, Loss: 2.161 Name: Delgado          Language: Portuguese       Classified as: Italian          Incorrect\n",
            "Example 38000, Loss: 1.109 Name: She              Language: Chinese          Classified as: Korean           Incorrect\n",
            "Example 39000, Loss: 0.912 Name: Song             Language: Korean           Classified as: Korean           Correct\n",
            "Example 40000, Loss: 1.872 Name: Maslanka         Language: Polish           Classified as: Czech            Incorrect\n",
            "Example 41000, Loss: 3.660 Name: Birich           Language: Russian          Classified as: Czech            Incorrect\n",
            "Example 42000, Loss: 0.404 Name: Pantelas         Language: Greek            Classified as: Greek            Correct\n",
            "Example 43000, Loss: 0.557 Name: Hyata            Language: Japanese         Classified as: Japanese         Correct\n",
            "Example 44000, Loss: 1.041 Name: Klerken          Language: Dutch            Classified as: Dutch            Correct\n",
            "Example 45000, Loss: 0.683 Name: Baukin           Language: Russian          Classified as: Russian          Correct\n",
            "Example 46000, Loss: 1.795 Name: Obando           Language: Spanish          Classified as: Russian          Incorrect\n",
            "Example 47000, Loss: 0.719 Name: Pantelas         Language: Greek            Classified as: Greek            Correct\n",
            "Example 48000, Loss: 0.552 Name: Travert          Language: French           Classified as: French           Correct\n",
            "Example 49000, Loss: 0.553 Name: Montanari        Language: Italian          Classified as: Italian          Correct\n",
            "Example 50000, Loss: 0.271 Name: Calogerakis      Language: Greek            Classified as: Greek            Correct\n",
            "Example 51000, Loss: 0.637 Name: Danas            Language: Greek            Classified as: Greek            Correct\n",
            "Example 52000, Loss: 2.951 Name: Kim              Language: Vietnamese       Classified as: Chinese          Incorrect\n",
            "Example 53000, Loss: 0.093 Name: Okimoto          Language: Japanese         Classified as: Japanese         Correct\n",
            "Example 54000, Loss: 0.792 Name: Kwang            Language: Korean           Classified as: Korean           Correct\n",
            "Example 55000, Loss: 1.082 Name: Bengochea        Language: Spanish          Classified as: Spanish          Correct\n",
            "Example 56000, Loss: 2.886 Name: Takecare         Language: Japanese         Classified as: Scottish         Incorrect\n",
            "Example 57000, Loss: 0.050 Name: Malinowski       Language: Polish           Classified as: Polish           Correct\n",
            "Example 58000, Loss: 3.429 Name: Vilmont          Language: Russian          Classified as: French           Incorrect\n",
            "Example 59000, Loss: 1.010 Name: Dupont           Language: French           Classified as: French           Correct\n",
            "Example 60000, Loss: 0.540 Name: Panayiotopoulos  Language: Greek            Classified as: Greek            Correct\n",
            "Example 61000, Loss: 3.118 Name: Fava             Language: Italian          Classified as: Czech            Incorrect\n",
            "Example 62000, Loss: 0.031 Name: O'Keefe          Language: Irish            Classified as: Irish            Correct\n",
            "Example 63000, Loss: 0.074 Name: Nelyubov         Language: Russian          Classified as: Russian          Correct\n",
            "Example 64000, Loss: 1.354 Name: Shirmankin       Language: Russian          Classified as: Scottish         Incorrect\n",
            "Example 65000, Loss: 0.754 Name: Kruger           Language: German           Classified as: German           Correct\n",
            "Example 66000, Loss: 0.822 Name: Langston         Language: English          Classified as: English          Correct\n",
            "Example 67000, Loss: 0.282 Name: Benini           Language: Italian          Classified as: Italian          Correct\n",
            "Example 68000, Loss: 3.756 Name: Kaiser           Language: Czech            Classified as: Arabic           Incorrect\n",
            "Example 69000, Loss: 5.878 Name: Vins             Language: Russian          Classified as: Vietnamese       Incorrect\n",
            "Example 70000, Loss: 1.997 Name: Vivas            Language: Spanish          Classified as: Greek            Incorrect\n",
            "Example 71000, Loss: 1.768 Name: Dubinin          Language: Russian          Classified as: Irish            Incorrect\n",
            "Example 72000, Loss: 1.419 Name: Korycansky       Language: Czech            Classified as: Polish           Incorrect\n",
            "Example 73000, Loss: 4.263 Name: Rompa            Language: Dutch            Classified as: Czech            Incorrect\n",
            "Example 74000, Loss: 2.953 Name: Johnston         Language: Scottish         Classified as: English          Incorrect\n",
            "Example 75000, Loss: 1.114 Name: Lorenzen         Language: German           Classified as: German           Correct\n",
            "Example 76000, Loss: 0.577 Name: Favager          Language: French           Classified as: French           Correct\n",
            "Example 77000, Loss: 4.602 Name: Vo               Language: German           Classified as: Vietnamese       Incorrect\n",
            "Example 78000, Loss: 2.684 Name: Dagher           Language: Arabic           Classified as: French           Incorrect\n",
            "Example 79000, Loss: 2.583 Name: Antonowitz       Language: Czech            Classified as: Polish           Incorrect\n",
            "Example 80000, Loss: 1.947 Name: Pavlunovsky      Language: Russian          Classified as: Czech            Incorrect\n",
            "Example 81000, Loss: 0.737 Name: Ra               Language: Korean           Classified as: Korean           Correct\n",
            "Example 82000, Loss: 0.354 Name: Sutherland       Language: Scottish         Classified as: Scottish         Correct\n",
            "Example 83000, Loss: 5.606 Name: Balazowski       Language: Russian          Classified as: Polish           Incorrect\n",
            "Example 84000, Loss: 1.024 Name: Fionn            Language: Irish            Classified as: Irish            Correct\n",
            "Example 85000, Loss: 2.172 Name: Loifman          Language: Russian          Classified as: French           Incorrect\n",
            "Example 86000, Loss: 0.194 Name: Minami           Language: Japanese         Classified as: Japanese         Correct\n",
            "Example 87000, Loss: 0.525 Name: Nicolai          Language: Italian          Classified as: Italian          Correct\n",
            "Example 88000, Loss: 4.248 Name: Fabian           Language: Polish           Classified as: French           Incorrect\n",
            "Example 89000, Loss: 0.198 Name: Malihoudis       Language: Greek            Classified as: Greek            Correct\n",
            "Example 90000, Loss: 3.116 Name: Blanchett        Language: French           Classified as: Scottish         Incorrect\n",
            "Example 91000, Loss: 0.397 Name: Dertilis         Language: Greek            Classified as: Greek            Correct\n",
            "Example 92000, Loss: 1.602 Name: Ahn              Language: Korean           Classified as: Vietnamese       Incorrect\n",
            "Example 93000, Loss: 2.465 Name: Luscombe         Language: English          Classified as: French           Incorrect\n",
            "Example 94000, Loss: 1.537 Name: San              Language: Korean           Classified as: Chinese          Incorrect\n",
            "Example 95000, Loss: 1.236 Name: Torrens          Language: English          Classified as: English          Correct\n",
            "Example 96000, Loss: 1.891 Name: Silva            Language: Portuguese       Classified as: Czech            Incorrect\n",
            "Example 97000, Loss: 0.410 Name: Nahas            Language: Arabic           Classified as: Arabic           Correct\n",
            "Example 98000, Loss: 3.720 Name: Ebsvort          Language: Russian          Classified as: French           Incorrect\n",
            "Example 99000, Loss: 2.441 Name: Dobbin           Language: English          Classified as: Russian          Incorrect\n",
            "Example 100000, Loss: 0.295 Name: Jackson          Language: Scottish         Classified as: Scottish         Correct\n"
          ]
        }
      ],
      "source": [
        "\n",
        "n_iters = 100000\n",
        "\n",
        "for i in range(1, n_iters + 1):\n",
        "  language, name, lang_tensor, name_tensor = random_train_example()\n",
        "  output, loss = train_on_example(name_tensor, lang_tensor)\n",
        "\n",
        "  if not i % 1000:\n",
        "    lang_pred = languages[torch.argmax(output).item()]\n",
        "\n",
        "    print(f'Example {i}, Loss: {loss:.3f} Name: {name:16s} Language: {language:16s} Classified as: {lang_pred:16s} {\"Correct\" if lang_pred == language else \"Incorrect\"}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbACHnfkXuq9"
      },
      "source": [
        "### Evaluating the network\n",
        "\n",
        "We now define a function that gives the network names you can enter manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FDN60k38XVAw"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def predict(input_name, num_langs=3):\n",
        "  name_tensor = lineToTensor(input_name)\n",
        "  hidden_state = torch.zeros(1, n_hidden)\n",
        "  for character_tensor in name_tensor:\n",
        "    out, hidden_state = rnn(character_tensor, hidden_state)\n",
        "\n",
        "  dist = list(zip(languages, F.softmax(out, dim=1).squeeze()))\n",
        "\n",
        "  topk_langs = sorted(dist, key=lambda p: p[1].item())[-num_langs:]\n",
        "\n",
        "  for lang, p in reversed(topk_langs):\n",
        "    print(f'{lang}, {p.item()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-qOBToI1N3XW",
        "outputId": "fdf18643-cb40-4e19-ee43-bc7ed4263ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Swennenhuis\n",
            "Greek, 0.31973791122436523\n",
            "Chinese, 0.260838121175766\n",
            "German, 0.11436771601438522\n",
            "Hoomans\n",
            "Japanese, 0.3085389733314514\n",
            "Dutch, 0.2575110197067261\n",
            "Greek, 0.15522971749305725\n",
            "Niewzwaag\n",
            "Polish, 0.5414565801620483\n",
            "Japanese, 0.19971954822540283\n",
            "Chinese, 0.06976649165153503\n",
            "Ho\n",
            "Korean, 0.47006720304489136\n",
            "Vietnamese, 0.38509610295295715\n",
            "Chinese, 0.06537957489490509\n",
            "Puslys\n",
            "Greek, 0.3157508373260498\n",
            "English, 0.2180025428533554\n",
            "Japanese, 0.08167218416929245\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-551169845.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "while(True):\n",
        "  predict(input(\\))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "RNN_for_name_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}